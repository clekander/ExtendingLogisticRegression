{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d336ca",
   "metadata": {},
   "source": [
    "# Lab Assignment 3: Extending Logistic Regression\n",
    "\n",
    "Gabs DiLiegro, London Kasper, Carys LeKander\n",
    "\n",
    "# 1. Preparation and Overview\n",
    "\n",
    "Our dataset is centered around housing in neighborhoods around Melbourne, Australia. Our classification task is based on the prices of the housing. We have separated our data into three categories (less than 500,000, 500,000 - 1,000,000, and greater than 1,000,000). Being able to predict what range the housing cost lies in could help buyers and sellers in the housing market as people looking to buy a house could use this model to see what factors drive prices up and be able to stay in their price range and sellers could get an accurate estimate of how much their home is worth. \n",
    "\n",
    "We believe that the accuracy of our model would need to be a high percentage to be accepted by users because there are many algorithms about predicting housing prices that currently exist with high accuracy. When looking online, we found multiple tools built to forecast prices of homes (ex. VeroFORECAST) and research papers about machine learning for predicting housing costs (ex. one we found claims 86% accuracy). \n",
    "\n",
    "*COST OF MISCLASIFICATION*\n",
    "\n",
    "\n",
    "*WHY IS IT GOOD ENOUGH FOR STAKEHOLDERS*\n",
    "\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/dansbecker/melbourne-housing-snapshot\n",
    "\n",
    "******************************************************\n",
    "\n",
    "VeroFORCAST: https://www.veros.com/solutions/home-price-trends-and-forecast/veroforecast\n",
    "\n",
    "Reasearch paper example: https://www.ijert.org/comparison-of-machine-learning-algorithms-for-house-price-prediction-using-real-time-data\n",
    "\n",
    "\n",
    "## Define and Prepare Classs Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f05bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Suburb         13580 non-null  object \n",
      " 1   Address        13580 non-null  object \n",
      " 2   Rooms          13580 non-null  int64  \n",
      " 3   Type           13580 non-null  object \n",
      " 4   Price          13580 non-null  float64\n",
      " 5   Method         13580 non-null  object \n",
      " 6   SellerG        13580 non-null  object \n",
      " 7   Date           13580 non-null  object \n",
      " 8   Distance       13580 non-null  float64\n",
      " 9   Postcode       13580 non-null  float64\n",
      " 10  Bedroom2       13580 non-null  float64\n",
      " 11  Bathroom       13580 non-null  float64\n",
      " 12  Car            13518 non-null  float64\n",
      " 13  Landsize       13580 non-null  float64\n",
      " 14  BuildingArea   7130 non-null   float64\n",
      " 15  YearBuilt      8205 non-null   float64\n",
      " 16  CouncilArea    12211 non-null  object \n",
      " 17  Lattitude      13580 non-null  float64\n",
      " 18  Longtitude     13580 non-null  float64\n",
      " 19  Regionname     13580 non-null  object \n",
      " 20  Propertycount  13580 non-null  float64\n",
      "dtypes: float64(12), int64(1), object(8)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "df = pd.read_csv('melb_data.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e824fd43",
   "metadata": {},
   "source": [
    "In Assingment 1, we explained why we decided to remove certain attributes. We have listed descriptions of the attributes used and removed below.\n",
    "\n",
    "### Attributes used:\n",
    "- Suburb: the name of the suburb that each property is in. (String object)\n",
    "- Rooms: the total number of rooms for each property. (int64)\n",
    "- Type: the type of property. ( h = house; u = unit, duplex; t = townhouse)\n",
    "- Price: listing price in Australian dollars (float64)\n",
    "- Distance: the distance from the property to the Melbourne central business district AKA CBD (float64)\n",
    "- Postcode: zipcode the property falls within (float64) \n",
    "- Bathroom: the number of bathrooms (float64)\n",
    "- Car: the number of parking spots (float64)\n",
    "- Landsize: the size of the land in meters (float64)\n",
    "- Regionname: general region of the property (String object)\n",
    "\n",
    "### Attributes removed and why:\n",
    "- Address: the address of the property (String object)\n",
    "- Method: way the property was listed\n",
    "     - We aren't considering data about how the house was sold, just the features of the house itself, which is why we also excluded SellerG and Date\n",
    "- SellerG: name of the real estate agent listing the property (String object)\n",
    "- Date: sale date in mm/dd/yyyy (float64)\n",
    "- Bedroom2: the number of bedrooms (float64: scraped from a different source)\n",
    "    - Rooms and Bedroom2 contain the same information collected from different sources. We have seen that these features are very strongly correlated and have very similar data, so we are excluding Bedroom2 for simplicity.\n",
    "- Propertycount: number of properties in the same suburb (float64)\n",
    "- BuildingArea: area of the building in meters\n",
    "    - Since ~47% of the dataset is missing this we decided to remove it\n",
    "- YearBuilt: year the house was built (float64)\n",
    "    - Although we think YearBuilt could have useful infomation for our model, ~40% of the data is missing so we have decided to remove it\n",
    "- CouncilArea: the governing council for the area (String object)\n",
    "    - The CouncilArea stopped being recorded after a certain date. Therefore we decided to remove this attribute as we did not want it to skew our set\n",
    "- Latitude: lattitude of property (float64)\n",
    "- Longitude: longtitude of property (float64)\n",
    "    - Niether Longitude or Latitude supply us with more useful information than other data we have collected about the area of the houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f751bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing irrelevant columns \n",
    "df = df.drop(['Address','Method','SellerG', 'Date','Bedroom2', 'Propertycount','BuildingArea', 'YearBuilt','CouncilArea','Lattitude','Longtitude'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a16d5a",
   "metadata": {},
   "source": [
    "Our only column remaining with missing data is the car spots. There are only 62 missing data points of 13,580."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70cfad11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13518.000000\n",
       "mean         1.610075\n",
       "std          0.962634\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          2.000000\n",
       "max         10.000000\n",
       "Name: Car, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Car.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2285a9f",
   "metadata": {},
   "source": [
    "Since there are so few missing points and the interquartile range is small, we used the median (2 spots) to fill the missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd2a4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Suburb      13580 non-null  object \n",
      " 1   Rooms       13580 non-null  int64  \n",
      " 2   Type        13580 non-null  object \n",
      " 3   Price       13580 non-null  float64\n",
      " 4   Distance    13580 non-null  float64\n",
      " 5   Postcode    13580 non-null  float64\n",
      " 6   Bathroom    13580 non-null  float64\n",
      " 7   Car         13580 non-null  float64\n",
      " 8   Landsize    13580 non-null  float64\n",
      " 9   Regionname  13580 non-null  object \n",
      "dtypes: float64(6), int64(1), object(3)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#fill in missing numeric values with median for Car\n",
    "df.Car = df.Car.fillna(df.Car.median())\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a3d4db",
   "metadata": {},
   "source": [
    "Next, we want to normalize our numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09fc6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols_to_norm = ['Rooms','Distance','Bathroom','Car','Landsize']\n",
    "df[cols_to_norm] = MinMaxScaler().fit_transform(df[cols_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4858dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Regionname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>h</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>h</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>h</td>\n",
       "      <td>850000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>h</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Suburb     Rooms Type      Price  Distance  Postcode  Bathroom  Car  \\\n",
       "0  Abbotsford  0.111111    h  1480000.0  0.051975    3067.0     0.125  0.1   \n",
       "1  Abbotsford  0.111111    h  1035000.0  0.051975    3067.0     0.125  0.0   \n",
       "2  Abbotsford  0.222222    h  1465000.0  0.051975    3067.0     0.250  0.0   \n",
       "3  Abbotsford  0.222222    h   850000.0  0.051975    3067.0     0.250  0.1   \n",
       "4  Abbotsford  0.333333    h  1600000.0  0.051975    3067.0     0.125  0.2   \n",
       "\n",
       "   Landsize             Regionname  \n",
       "0  0.000466  Northern Metropolitan  \n",
       "1  0.000360  Northern Metropolitan  \n",
       "2  0.000309  Northern Metropolitan  \n",
       "3  0.000217  Northern Metropolitan  \n",
       "4  0.000277  Northern Metropolitan  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aeb473",
   "metadata": {},
   "source": [
    "Then, we one-hot encode our categorical data.\n",
    "\n",
    "Type has 3 unqiue values ('h' for house, 'u' for unit, and 't' for townhouse) and Regionname has 8 unique regions. We one-hot encode those below and show the new variables we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c26c583c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Suburb                                 13580 non-null  object \n",
      " 1   Rooms                                  13580 non-null  float64\n",
      " 2   Price                                  13580 non-null  float64\n",
      " 3   Distance                               13580 non-null  float64\n",
      " 4   Postcode                               13580 non-null  float64\n",
      " 5   Bathroom                               13580 non-null  float64\n",
      " 6   Car                                    13580 non-null  float64\n",
      " 7   Landsize                               13580 non-null  float64\n",
      " 8   Type_h                                 13580 non-null  uint8  \n",
      " 9   Type_t                                 13580 non-null  uint8  \n",
      " 10  Type_u                                 13580 non-null  uint8  \n",
      " 11  Regionname_Eastern Metropolitan        13580 non-null  uint8  \n",
      " 12  Regionname_Eastern Victoria            13580 non-null  uint8  \n",
      " 13  Regionname_Northern Metropolitan       13580 non-null  uint8  \n",
      " 14  Regionname_Northern Victoria           13580 non-null  uint8  \n",
      " 15  Regionname_South-Eastern Metropolitan  13580 non-null  uint8  \n",
      " 16  Regionname_Southern Metropolitan       13580 non-null  uint8  \n",
      " 17  Regionname_Western Metropolitan        13580 non-null  uint8  \n",
      " 18  Regionname_Western Victoria            13580 non-null  uint8  \n",
      "dtypes: float64(7), object(1), uint8(11)\n",
      "memory usage: 994.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df,pd.get_dummies(df['Type'], prefix='Type')],axis=1)\n",
    "df.drop(['Type'],axis=1, inplace=True)\n",
    "\n",
    "df = pd.concat([df,pd.get_dummies(df['Regionname'], prefix='Regionname')],axis=1)\n",
    "df.drop(['Regionname'],axis=1, inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cd97c3",
   "metadata": {},
   "source": [
    "Postcode and Suburb have way more unique values. We one-hot encode them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "382cbea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Columns: 529 entries, Rooms to Suburb_Yarraville\n",
      "dtypes: float64(6), uint8(523)\n",
      "memory usage: 7.4 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df,pd.get_dummies(df['Postcode'], prefix='Postcode')],axis=1)\n",
    "df.drop(['Postcode'],axis=1, inplace=True)\n",
    "\n",
    "df = pd.concat([df,pd.get_dummies(df['Suburb'], prefix='Suburb')],axis=1)\n",
    "df.drop(['Suburb'],axis=1, inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d318e",
   "metadata": {},
   "source": [
    "## Divide Data:\n",
    "\n",
    "Now getting ready to split our testing and training data, we define the bins for our price ranges and labeling those groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eda3d11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Type_h</th>\n",
       "      <th>Type_t</th>\n",
       "      <th>Type_u</th>\n",
       "      <th>Regionname_Eastern Metropolitan</th>\n",
       "      <th>...</th>\n",
       "      <th>Suburb_Williamstown</th>\n",
       "      <th>Suburb_Williamstown North</th>\n",
       "      <th>Suburb_Windsor</th>\n",
       "      <th>Suburb_Wollert</th>\n",
       "      <th>Suburb_Wonga Park</th>\n",
       "      <th>Suburb_Wyndham Vale</th>\n",
       "      <th>Suburb_Yallambie</th>\n",
       "      <th>Suburb_Yarra Glen</th>\n",
       "      <th>Suburb_Yarraville</th>\n",
       "      <th>Price_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>850000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 530 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rooms      Price  Distance  Bathroom  Car  Landsize  Type_h  Type_t  \\\n",
       "0  0.111111  1480000.0  0.051975     0.125  0.1  0.000466       1       0   \n",
       "1  0.111111  1035000.0  0.051975     0.125  0.0  0.000360       1       0   \n",
       "2  0.222222  1465000.0  0.051975     0.250  0.0  0.000309       1       0   \n",
       "3  0.222222   850000.0  0.051975     0.250  0.1  0.000217       1       0   \n",
       "4  0.333333  1600000.0  0.051975     0.125  0.2  0.000277       1       0   \n",
       "\n",
       "   Type_u  Regionname_Eastern Metropolitan  ...  Suburb_Williamstown  \\\n",
       "0       0                                0  ...                    0   \n",
       "1       0                                0  ...                    0   \n",
       "2       0                                0  ...                    0   \n",
       "3       0                                0  ...                    0   \n",
       "4       0                                0  ...                    0   \n",
       "\n",
       "   Suburb_Williamstown North  Suburb_Windsor  Suburb_Wollert  \\\n",
       "0                          0               0               0   \n",
       "1                          0               0               0   \n",
       "2                          0               0               0   \n",
       "3                          0               0               0   \n",
       "4                          0               0               0   \n",
       "\n",
       "   Suburb_Wonga Park  Suburb_Wyndham Vale  Suburb_Yallambie  \\\n",
       "0                  0                    0                 0   \n",
       "1                  0                    0                 0   \n",
       "2                  0                    0                 0   \n",
       "3                  0                    0                 0   \n",
       "4                  0                    0                 0   \n",
       "\n",
       "   Suburb_Yarra Glen  Suburb_Yarraville  Price_Category  \n",
       "0                  0                  0               2  \n",
       "1                  0                  0               2  \n",
       "2                  0                  0               2  \n",
       "3                  0                  0               1  \n",
       "4                  0                  0               2  \n",
       "\n",
       "[5 rows x 530 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0, 500000, 1000000, 10000000]\n",
    "category = [0, 1, 2]\n",
    "df['Price_Category'] = pd.cut(df['Price'], bins, labels=category)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026ff88",
   "metadata": {},
   "source": [
    "Next, we define our y that will be used when we test and train and remove the price and categorical price from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8062775d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6240\n",
       "2    5743\n",
       "0    1597\n",
       "Name: Price_Category, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals = df['Price_Category'].value_counts()\n",
    "y = df.Price_Category\n",
    "df.drop(['Price'],axis=1, inplace=True)\n",
    "df.drop(['Price_Category'],axis=1, inplace=True)\n",
    "totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15418eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, train_size=0.8, shuffle=True)\n",
    "y_train = y_train.values.tolist()\n",
    "y_test = y_test.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19466cae",
   "metadata": {},
   "source": [
    "*WHY 80/20 SPLIT WORKS?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9012a",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2783b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d822994",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegressionBase:\n",
    "    # private:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Base Binary Logistic Regression Object, Not Trainable'\n",
    "    \n",
    "    # convenience, private and static:\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return 1/(1+np.exp(-theta)) \n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self, X, add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89856822",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression(BinaryLogisticRegressionBase):\n",
    "    #private:\n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    def _get_gradient(self,X,y):\n",
    "        # programming \\sum_i (yi-g(xi))xi\n",
    "        gradient = np.zeros(self.w_.shape) # set gradient to zero\n",
    "        for (xi,yi) in zip(X,y):\n",
    "            # the actual update inside of sum\n",
    "            gradi = (yi - self.predict_proba(xi,add_bias=False))*xi \n",
    "            # reshape to be column vector and add to gradient\n",
    "            gradient += gradi.reshape(self.w_.shape) \n",
    "        \n",
    "        return gradient/float(len(y))\n",
    "       \n",
    "    # public:\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc60d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # inherit from our previous class to get same functionality\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # but overwrite the gradient calculation\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        gradient.reshape(self.w_.shape)\n",
    "        if(regularization == 'L1'):\n",
    "            gradient = RegularizedL1BinaryLogisticRegression(gradient, self.c)\n",
    "        elif(regularization == 'L2'):\n",
    "            gradient = RegularizedL2BinaryLogisticRegression(gradient, self.c)\n",
    "        elif(regularization == 'both'):\n",
    "            gradient = RegularizedBothBinaryLogisticRegression(gradient, self.c)\n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbe15fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HessianBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    def __init__(self, regularization, C, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.regularization = regularization\n",
    "        self.C = C\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds) # call parent initializer\n",
    "    # just overwrite gradient function\n",
    "    def _get_gradient(self,X,y):\n",
    "        g = self.predict_proba(X,add_bias=False).ravel() # get sigmoid value for all classes\n",
    "        hessian = X.T @ np.diag(g*(1-g)) @ X - 2 * self.C # calculate the hessian\n",
    "\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.sum(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        if(self.regularization == 'L1'):\n",
    "            gradient[1:] += (self.w_[1:]/abs(self.w_[1:])) * self.C\n",
    "        elif(self.regularization == 'L2'):\n",
    "            gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        elif(self.regularization == 'both'):\n",
    "            gradient = (self.w_[1:]/abs(self.w_[1:])) * self.C + -2 * self.w_[1:] * self.C\n",
    "\n",
    "        return pinv(hessian) @ gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68280f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularizedL2BinaryLogisticRegression(VectorBinaryLogisticRegression):\n",
    "    # extend init functions\n",
    "    def __init__(self, C=0.0, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.C = C\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds) # call parent initializer\n",
    "        \n",
    "        \n",
    "    # extend previous class to change functionality\n",
    "    def _get_gradient(self,X,y):\n",
    "        # call get gradient from previous class\n",
    "        gradient = super()._get_gradient(X,y)\n",
    "        \n",
    "        # add in regularization (to all except bias term)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a981ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularizedL1BinaryLogisticRegression(VectorBinaryLogisticRegression):\n",
    "    # extend init functions\n",
    "    def __init__(self, C=0.0, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.C = C\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds) # call parent initializer\n",
    "        \n",
    "        \n",
    "    # extend previous class to change functionality\n",
    "    def _get_gradient(self,X,y):\n",
    "        # call get gradient from previous class\n",
    "        gradient = super()._get_gradient(X,y)\n",
    "        \n",
    "        # add in regularization (to all except bias term)\n",
    "        gradient[1:] += (self.w_[1:]/abs.self.w_[1:]) * self.C\n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c9adfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularizedBothBinaryLogisticRegression(VectorBinaryLogisticRegression):\n",
    "    # extend init functions\n",
    "    def __init__(self, C=0.0, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.C = C\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds) # call parent initializer\n",
    "        \n",
    "        \n",
    "    # extend previous class to change functionality\n",
    "    def _get_gradient(self,X,y):\n",
    "        # call get gradient from previous class\n",
    "        gradient = super()._get_gradient(X,y)\n",
    "        \n",
    "        # add in regularization (to all except bias term)\n",
    "        gradient[1:] += ((self.w_[1:]/abs.self.w_[1:]) * self.C) + -2 * self.w_[1:] * self.C\n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "493d6387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RegularizedBothBinaryLogisticRegression(gradient, C, w):\n",
    "    gradient[1:] += ((w[1:]/abs.w[1:]) * C) + -2 * w[1:] * C\n",
    "    return gradient\n",
    "\n",
    "def RegularizedL1BinaryLogisticRegression(gradient, C, w):\n",
    "    gradient[1:] += (w[1:]/abs(w[1:])) * C\n",
    "    return gradient\n",
    "\n",
    "def RegularizedL2BinaryLogisticRegression(gradient, c, w):\n",
    "    gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec14dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticLogisticRegression(BinaryLogisticRegression):\n",
    "    def __init__(self, regularization, C, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.regularization = regularization\n",
    "        self.C = C\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds) # call parent initializer\n",
    "    # stochastic gradient calculation \n",
    "    def _get_gradient(self,X,y):\n",
    "        idx = int(np.random.rand()*len(y)) # grab random instance\n",
    "        ydiff = y[idx]-self.predict_proba(X[idx],add_bias=False) # get y difference (now scalar)\n",
    "        gradient = X[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        if(self.regularization == 'L1'):\n",
    "            gradient[1:] += (self.w_[1:]/abs(self.w_[1:])) * self.C\n",
    "        elif(self.regularization == 'L2'):\n",
    "            gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        elif(self.regularization == 'both'):\n",
    "            gradient = (self.w_[1:]/abs(self.w_[1:])) * self.C + -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68023a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, eta, optimization, regularization='none', C = 0.0, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.optimization = optimization\n",
    "        self.regularization = regularization\n",
    "        self.C = C\n",
    "                    \n",
    "    # inherit from our previous class to get same functionality\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # but overwrite the gradient calculation\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        return gradient.reshape(self.w_.shape)(self.eta, self.iters)\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = (y==yval) # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            \n",
    "            if(self.optimization == 'Hessian'):\n",
    "                blr = HessianBinaryLogisticRegression(regularization=self.regularization, C=self.C, eta=self.eta, iterations=self.iters )\n",
    "                self.classifiers_.append(blr)\n",
    "\n",
    "            elif(self.optimization == 'Stochastic'):\n",
    "                blr = StochasticLogisticRegression(regularization=self.regularization, C=self.C, eta=self.eta, iterations=self.iters )\n",
    "                self.classifiers_.append(blr)\n",
    "\n",
    "            else:\n",
    "                blr = RegularizedBothLogisticRegression(eta=self.eta, iterations=self.iters, C=self.C)\n",
    "                self.classifiers_.append(blr)\n",
    "\n",
    "            # add the trained classifier to the list\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return self.unique_[np.argmax(self.predict_proba(X),axis=1)] # take argmax along row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a80feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import pinv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c61880c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(eta=0.1,\n",
    "                                       optimization = 'Stochastic',\n",
    "                                       regularization = 'L2',# lots of iterations (to help overfit)\n",
    "                                        C=.01,\n",
    "                                      iterations = 20) # get object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09580c02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlr_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifiers_\u001b[38;5;241m.\u001b[39mappend(blr)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStochastic\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 44\u001b[0m     blr \u001b[38;5;241m=\u001b[39m StochasticLogisticRegression(regularization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregularization, C\u001b[38;5;241m=\u001b[39m\u001b[43mC\u001b[49m, eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miters )\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifiers_\u001b[38;5;241m.\u001b[39mappend(blr)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129413e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "yhat = lr_clf.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))\n",
    "print(yhat[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3812c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe0e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e83128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "\n",
    "lr_sk = SKLogisticRegression(solver='liblinear') # all params default\n",
    "\n",
    "lr_sk.fit(X_train,y_train)\n",
    "yhat = lr_sk.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))\n",
    "\n",
    "print(yhat[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d26a318",
   "metadata": {},
   "source": [
    "# 3. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02799f81",
   "metadata": {},
   "source": [
    "# 4. Exceptional Work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
