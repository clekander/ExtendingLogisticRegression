{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d336ca",
   "metadata": {},
   "source": [
    "# Lab Assignment 3: Extending Logistic Regression\n",
    "\n",
    "Gabs DiLiegro, London Kasper, Carys LeKander\n",
    "\n",
    "# 1. Preparation and Overview\n",
    "\n",
    "Our dataset is centered around housing in neighborhoods around Melbourne, Australia. Our classification task is based on the prices of the housing. We have separated our data into three categories (less than 500,000, 500,000 - 1,000,000, and greater than 1,000,000). Being able to predict what range the housing cost lies in could help buyers and sellers in the housing market as people looking to buy a house could use this model to see what factors drive prices up and be able to stay in their price range and sellers could get an accurate estimate of how much their home is worth. \n",
    "\n",
    "We believe that the accuracy of our model would need to be a high percentage to be accepted by users because there are many algorithms about predicting housing prices that currently exist with high accuracy. When looking online, we found multiple tools built to forecast prices of homes (ex. VeroFORECAST) and research papers about machine learning for predicting housing costs (ex. one we found claims 86% accuracy). \n",
    "\n",
    "*COST OF MISCLASIFICATION*\n",
    "\n",
    "\n",
    "*WHY IS IT GOOD ENOUGH FOR STAKEHOLDERS*\n",
    "\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/dansbecker/melbourne-housing-snapshot\n",
    "\n",
    "******************************************************\n",
    "\n",
    "VeroFORCAST: https://www.veros.com/solutions/home-price-trends-and-forecast/veroforecast\n",
    "\n",
    "Reasearch paper example: https://www.ijert.org/comparison-of-machine-learning-algorithms-for-house-price-prediction-using-real-time-data\n",
    "\n",
    "\n",
    "## Define and Prepare Classs Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f05bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Suburb         13580 non-null  object \n",
      " 1   Address        13580 non-null  object \n",
      " 2   Rooms          13580 non-null  int64  \n",
      " 3   Type           13580 non-null  object \n",
      " 4   Price          13580 non-null  float64\n",
      " 5   Method         13580 non-null  object \n",
      " 6   SellerG        13580 non-null  object \n",
      " 7   Date           13580 non-null  object \n",
      " 8   Distance       13580 non-null  float64\n",
      " 9   Postcode       13580 non-null  float64\n",
      " 10  Bedroom2       13580 non-null  float64\n",
      " 11  Bathroom       13580 non-null  float64\n",
      " 12  Car            13518 non-null  float64\n",
      " 13  Landsize       13580 non-null  float64\n",
      " 14  BuildingArea   7130 non-null   float64\n",
      " 15  YearBuilt      8205 non-null   float64\n",
      " 16  CouncilArea    12211 non-null  object \n",
      " 17  Lattitude      13580 non-null  float64\n",
      " 18  Longtitude     13580 non-null  float64\n",
      " 19  Regionname     13580 non-null  object \n",
      " 20  Propertycount  13580 non-null  float64\n",
      "dtypes: float64(12), int64(1), object(8)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "df = pd.read_csv('melb_data.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e824fd43",
   "metadata": {},
   "source": [
    "In Assingment 1, we explained why we decided to remove certain attributes. We have listed descriptions of the attributes used and removed below.\n",
    "\n",
    "### Attributes used:\n",
    "- Suburb: the name of the suburb that each property is in. (String object)\n",
    "- Rooms: the total number of rooms for each property. (int64)\n",
    "- Type: the type of property. ( h = house; u = unit, duplex; t = townhouse)\n",
    "- Price: listing price in Australian dollars (float64)\n",
    "- Distance: the distance from the property to the Melbourne central business district AKA CBD (float64)\n",
    "- Postcode: zipcode the property falls within (float64) \n",
    "- Bathroom: the number of bathrooms (float64)\n",
    "- Car: the number of parking spots (float64)\n",
    "- Landsize: the size of the land in meters (float64)\n",
    "- Regionname: general region of the property (String object)\n",
    "\n",
    "### Attributes removed and why:\n",
    "- Address: the address of the property (String object)\n",
    "- Method: way the property was listed\n",
    "     - We aren't considering data about how the house was sold, just the features of the house itself, which is why we also excluded SellerG and Date\n",
    "- SellerG: name of the real estate agent listing the property (String object)\n",
    "- Date: sale date in mm/dd/yyyy (float64)\n",
    "- Bedroom2: the number of bedrooms (float64: scraped from a different source)\n",
    "    - Rooms and Bedroom2 contain the same information collected from different sources. We have seen that these features are very strongly correlated and have very similar data, so we are excluding Bedroom2 for simplicity.\n",
    "- Propertycount: number of properties in the same suburb (float64)\n",
    "- BuildingArea: area of the building in meters\n",
    "    - Since ~47% of the dataset is missing this we decided to remove it\n",
    "- YearBuilt: year the house was built (float64)\n",
    "    - Although we think YearBuilt could have useful infomation for our model, ~40% of the data is missing so we have decided to remove it\n",
    "- CouncilArea: the governing council for the area (String object)\n",
    "    - The CouncilArea stopped being recorded after a certain date. Therefore we decided to remove this attribute as we did not want it to skew our set\n",
    "- Latitude: lattitude of property (float64)\n",
    "- Longitude: longtitude of property (float64)\n",
    "    - Niether Longitude or Latitude supply us with more useful information than other data we have collected about the area of the houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f751bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing irrelevant columns \n",
    "df = df.drop(['Address','Method','SellerG', 'Date','Bedroom2', 'Propertycount','BuildingArea', 'YearBuilt','CouncilArea','Lattitude','Longtitude'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a16d5a",
   "metadata": {},
   "source": [
    "Our only column remaining with missing data is the car spots. There are only 62 missing data points of 13,580."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70cfad11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13518.000000\n",
       "mean         1.610075\n",
       "std          0.962634\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          2.000000\n",
       "max         10.000000\n",
       "Name: Car, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Car.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2285a9f",
   "metadata": {},
   "source": [
    "Since there are so few missing points and the interquartile range is small, we used the median (2 spots) to fill the missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd2a4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Suburb      13580 non-null  object \n",
      " 1   Rooms       13580 non-null  int64  \n",
      " 2   Type        13580 non-null  object \n",
      " 3   Price       13580 non-null  float64\n",
      " 4   Distance    13580 non-null  float64\n",
      " 5   Postcode    13580 non-null  float64\n",
      " 6   Bathroom    13580 non-null  float64\n",
      " 7   Car         13580 non-null  float64\n",
      " 8   Landsize    13580 non-null  float64\n",
      " 9   Regionname  13580 non-null  object \n",
      "dtypes: float64(6), int64(1), object(3)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#fill in missing numeric values with median for Car\n",
    "df.Car = df.Car.fillna(df.Car.median())\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a3d4db",
   "metadata": {},
   "source": [
    "Next, we want to normalize our numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09fc6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols_to_norm = ['Rooms','Distance','Bathroom','Car','Landsize']\n",
    "df[cols_to_norm] = MinMaxScaler().fit_transform(df[cols_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4858dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Regionname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>h</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>h</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>h</td>\n",
       "      <td>850000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>h</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Suburb     Rooms Type      Price  Distance  Postcode  Bathroom  Car  \\\n",
       "0  Abbotsford  0.111111    h  1480000.0  0.051975    3067.0     0.125  0.1   \n",
       "1  Abbotsford  0.111111    h  1035000.0  0.051975    3067.0     0.125  0.0   \n",
       "2  Abbotsford  0.222222    h  1465000.0  0.051975    3067.0     0.250  0.0   \n",
       "3  Abbotsford  0.222222    h   850000.0  0.051975    3067.0     0.250  0.1   \n",
       "4  Abbotsford  0.333333    h  1600000.0  0.051975    3067.0     0.125  0.2   \n",
       "\n",
       "   Landsize             Regionname  \n",
       "0  0.000466  Northern Metropolitan  \n",
       "1  0.000360  Northern Metropolitan  \n",
       "2  0.000309  Northern Metropolitan  \n",
       "3  0.000217  Northern Metropolitan  \n",
       "4  0.000277  Northern Metropolitan  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aeb473",
   "metadata": {},
   "source": [
    "Then, we one-hot encode our categorical data.\n",
    "\n",
    "Type has 3 unqiue values ('h' for house, 'u' for unit, and 't' for townhouse) and Regionname has 8 unique regions. We one-hot encode those below and show the new variables we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c26c583c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Suburb                                 13580 non-null  object \n",
      " 1   Rooms                                  13580 non-null  float64\n",
      " 2   Price                                  13580 non-null  float64\n",
      " 3   Distance                               13580 non-null  float64\n",
      " 4   Postcode                               13580 non-null  float64\n",
      " 5   Bathroom                               13580 non-null  float64\n",
      " 6   Car                                    13580 non-null  float64\n",
      " 7   Landsize                               13580 non-null  float64\n",
      " 8   Type_h                                 13580 non-null  uint8  \n",
      " 9   Type_t                                 13580 non-null  uint8  \n",
      " 10  Type_u                                 13580 non-null  uint8  \n",
      " 11  Regionname_Eastern Metropolitan        13580 non-null  uint8  \n",
      " 12  Regionname_Eastern Victoria            13580 non-null  uint8  \n",
      " 13  Regionname_Northern Metropolitan       13580 non-null  uint8  \n",
      " 14  Regionname_Northern Victoria           13580 non-null  uint8  \n",
      " 15  Regionname_South-Eastern Metropolitan  13580 non-null  uint8  \n",
      " 16  Regionname_Southern Metropolitan       13580 non-null  uint8  \n",
      " 17  Regionname_Western Metropolitan        13580 non-null  uint8  \n",
      " 18  Regionname_Western Victoria            13580 non-null  uint8  \n",
      "dtypes: float64(7), object(1), uint8(11)\n",
      "memory usage: 994.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df,pd.get_dummies(df['Type'], prefix='Type')],axis=1)\n",
    "df.drop(['Type'],axis=1, inplace=True)\n",
    "\n",
    "df = pd.concat([df,pd.get_dummies(df['Regionname'], prefix='Regionname')],axis=1)\n",
    "df.drop(['Regionname'],axis=1, inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cd97c3",
   "metadata": {},
   "source": [
    "Postcode and Suburb have way more unique values. We one-hot encode them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "382cbea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Columns: 529 entries, Rooms to Suburb_Yarraville\n",
      "dtypes: float64(6), uint8(523)\n",
      "memory usage: 7.4 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df,pd.get_dummies(df['Postcode'], prefix='Postcode')],axis=1)\n",
    "df.drop(['Postcode'],axis=1, inplace=True)\n",
    "\n",
    "df = pd.concat([df,pd.get_dummies(df['Suburb'], prefix='Suburb')],axis=1)\n",
    "df.drop(['Suburb'],axis=1, inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d318e",
   "metadata": {},
   "source": [
    "## Divide Data:\n",
    "\n",
    "Now getting ready to split our testing and training data, we define the bins for our price ranges and labeling those groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eda3d11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Type_h</th>\n",
       "      <th>Type_t</th>\n",
       "      <th>Type_u</th>\n",
       "      <th>Regionname_Eastern Metropolitan</th>\n",
       "      <th>...</th>\n",
       "      <th>Suburb_Williamstown</th>\n",
       "      <th>Suburb_Williamstown North</th>\n",
       "      <th>Suburb_Windsor</th>\n",
       "      <th>Suburb_Wollert</th>\n",
       "      <th>Suburb_Wonga Park</th>\n",
       "      <th>Suburb_Wyndham Vale</th>\n",
       "      <th>Suburb_Yallambie</th>\n",
       "      <th>Suburb_Yarra Glen</th>\n",
       "      <th>Suburb_Yarraville</th>\n",
       "      <th>Price_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>850000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 530 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rooms      Price  Distance  Bathroom  Car  Landsize  Type_h  Type_t  \\\n",
       "0  0.111111  1480000.0  0.051975     0.125  0.1  0.000466       1       0   \n",
       "1  0.111111  1035000.0  0.051975     0.125  0.0  0.000360       1       0   \n",
       "2  0.222222  1465000.0  0.051975     0.250  0.0  0.000309       1       0   \n",
       "3  0.222222   850000.0  0.051975     0.250  0.1  0.000217       1       0   \n",
       "4  0.333333  1600000.0  0.051975     0.125  0.2  0.000277       1       0   \n",
       "\n",
       "   Type_u  Regionname_Eastern Metropolitan  ...  Suburb_Williamstown  \\\n",
       "0       0                                0  ...                    0   \n",
       "1       0                                0  ...                    0   \n",
       "2       0                                0  ...                    0   \n",
       "3       0                                0  ...                    0   \n",
       "4       0                                0  ...                    0   \n",
       "\n",
       "   Suburb_Williamstown North  Suburb_Windsor  Suburb_Wollert  \\\n",
       "0                          0               0               0   \n",
       "1                          0               0               0   \n",
       "2                          0               0               0   \n",
       "3                          0               0               0   \n",
       "4                          0               0               0   \n",
       "\n",
       "   Suburb_Wonga Park  Suburb_Wyndham Vale  Suburb_Yallambie  \\\n",
       "0                  0                    0                 0   \n",
       "1                  0                    0                 0   \n",
       "2                  0                    0                 0   \n",
       "3                  0                    0                 0   \n",
       "4                  0                    0                 0   \n",
       "\n",
       "   Suburb_Yarra Glen  Suburb_Yarraville  Price_Category  \n",
       "0                  0                  0               2  \n",
       "1                  0                  0               2  \n",
       "2                  0                  0               2  \n",
       "3                  0                  0               1  \n",
       "4                  0                  0               2  \n",
       "\n",
       "[5 rows x 530 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0, 500000, 1000000, 10000000]\n",
    "category = [0, 1, 2]\n",
    "df['Price_Category'] = pd.cut(df['Price'], bins, labels=category)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026ff88",
   "metadata": {},
   "source": [
    "Next, we define our y that will be used when we test and train and remove the price and categorical price from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8062775d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6240\n",
       "2    5743\n",
       "0    1597\n",
       "Name: Price_Category, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals = df['Price_Category'].value_counts()\n",
    "y = df.Price_Category\n",
    "df.drop(['Price'],axis=1, inplace=True)\n",
    "df.drop(['Price_Category'],axis=1, inplace=True)\n",
    "totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15418eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, train_size=0.8, shuffle=True)\n",
    "y_train = y_train.values.tolist()\n",
    "y_test = y_test.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19466cae",
   "metadata": {},
   "source": [
    "*WHY 80/20 SPLIT WORKS?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9012a",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "332e84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from numpy.linalg import pinv\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "from scipy.optimize import fmin_bfgs # maybe the most common bfgs algorithm in the world\n",
    "from numpy import ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8f4b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.001, regularization):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        self.regularization\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "        \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    # convenience, private:\n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # vectorized gradient calculation with regularization using L2 Norm\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self,X,add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate \n",
    "            # add bacause maximizing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2284f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticLogisticRegression(BinaryLogisticRegression):\n",
    "\n",
    "    def _get_gradient(self,X,y):\n",
    "        idx = int(np.random.rand()*len(y)) # grab random instance\n",
    "        ydiff = y[idx]-self.predict_proba(X[idx],add_bias=False) # get y difference (now scalar)\n",
    "        gradient = X[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        \n",
    "        if (self.regularization == 'L2'):\n",
    "            gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        elif(self.regularization == 'L1'):\n",
    "            gradient[1:] += (self.w_[1:]/abs(self.w_[1:])) * self.C\n",
    "        elif(self.regularization == 'both'):\n",
    "            gradient[1:] += ((self.w_[1:]/abs(self.w_[1:])) * self.C) + (-2 * self.w_[1:] * self.C)\n",
    "            \n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eba25d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HessianBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "        \n",
    "    def _get_gradient(self,X,y):\n",
    "        g = self.predict_proba(X,add_bias=False).ravel() # get sigmoid value for all classes\n",
    "        hessian = X.T @ np.diag(g*(1-g)) @ X - 2 * self.C # calculate the hessian\n",
    "\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.sum(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        \n",
    "        if (self.regularization == 'L2'):\n",
    "            gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        elif(self.regularization == 'L1'):\n",
    "            gradient[1:] += (self.w_[1:]/abs(self.w_[1:])) * self.C\n",
    "        elif(self.regularization == 'both'):\n",
    "            gradient[1:] += ((self.w_[1:]/abs(self.w_[1:])) * self.C) + (-2 * self.w_[1:] * self.C)\n",
    "            \n",
    "        \n",
    "        return pinv(hessian) @ gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abf40214",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFGSBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    \n",
    "    def objective_gradient(self,w,X,y,C):\n",
    "        g = expit(X @ w)\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0)\n",
    "        gradient = gradient.reshape(w.shape)\n",
    "        \n",
    "        \"\"\"if (self.regularization == 'L2'):\n",
    "            gradient[1:] += -2 * w[1:] * C\n",
    "        elif(self.regularization == 'L1'):\n",
    "            gradient[1:] += (w[1:]/abs(self.w_[1:])) * C\n",
    "        elif(self.regularization == 'both'):\n",
    "            gradient[1:] += ((w[1:]/abs(w[1:])) * C) + (-2 * w[1:] * C)\"\"\"\n",
    "        gradient[1:] += -2 * w[1:] * C\n",
    "        return -gradient\n",
    "    \n",
    "    def objective_function(w,X,y,C):\n",
    "        g = expit(X @ w)\n",
    "        # invert this because scipy minimizes, but we derived all formulas for maximzing\n",
    "        return -np.sum(ma.log(g[y==1]))-np.sum(ma.log(1-g[y==0])) + C*sum(w**2) \n",
    "        #-np.sum(y*np.log(g)+(1-y)*np.log(1-g))\n",
    "    \n",
    "    # just overwrite fit function\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = fmin_bfgs(self.objective_function, # what to optimize\n",
    "                            np.zeros((num_features,1)), # starting point\n",
    "                            fprime=self.objective_gradient, # gradient function\n",
    "                            args=(Xb,y,self.C), # extra args for gradient and objective function\n",
    "                            gtol=1e-03, # stopping criteria for gradient, |v_k|\n",
    "                            maxiter=self.iters, # stopping criteria iterations\n",
    "                            disp=False)\n",
    "        \n",
    "        self.w_ = self.w_.reshape((num_features,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d8fd862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassLogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, \n",
    "                 C=0.0001, \n",
    "                 solver=HessianBinaryLogisticRegression,\n",
    "                regularization='none'):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        self.solver = solver\n",
    "        self.classifiers_ = []\n",
    "        self.regularization = regularization\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.sort(np.unique(y)) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = []\n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = np.array(y==yval).astype(int) # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            \n",
    "            hblr = self.solver(eta=self.eta,iterations=self.iters,C=self.C, regularization = self.regularization)\n",
    "            hblr.fit(X,y_binary)\n",
    "\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(hblr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for hblr in self.classifiers_:\n",
    "            probs.append(hblr.predict_proba(X).reshape((len(X),1))) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_proba(X),axis=1) # take argmax along row\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e804c57",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "objective_function() takes 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m lr \u001b[38;5;241m=\u001b[39m MultiClassLogisticRegression(eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      2\u001b[0m                                   iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                   C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                   solver\u001b[38;5;241m=\u001b[39mBFGSBinaryLogisticRegression,\n\u001b[1;32m      5\u001b[0m                                   regularization\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m                                  )\n\u001b[0;32m----> 7\u001b[0m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mMultiClassLogisticRegression.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# train the binary classifier for this class\u001b[39;00m\n\u001b[1;32m     29\u001b[0m hblr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver(eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta,iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miters,C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC, regularization \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregularization)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mhblr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_binary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# add the trained classifier to the list\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifiers_\u001b[38;5;241m.\u001b[39mappend(hblr)\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mBFGSBinaryLogisticRegression.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     31\u001b[0m Xb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_bias(X) \u001b[38;5;66;03m# add bias term\u001b[39;00m\n\u001b[1;32m     32\u001b[0m num_samples, num_features \u001b[38;5;241m=\u001b[39m Xb\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_ \u001b[38;5;241m=\u001b[39m \u001b[43mfmin_bfgs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# what to optimize\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# starting point\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfprime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective_gradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# gradient function\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[43m                    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXb\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# extra args for gradient and objective function\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mgtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# stopping criteria for gradient, |v_k|\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# stopping criteria iterations\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_\u001b[38;5;241m.\u001b[39mreshape((num_features,\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py:1143\u001b[0m, in \u001b[0;36mfmin_bfgs\u001b[0;34m(f, x0, fprime, args, gtol, norm, epsilon, maxiter, full_output, disp, retall, callback)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;124;03mMinimize a function using the BFGS algorithm.\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \n\u001b[1;32m   1135\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgtol\u001b[39m\u001b[38;5;124m'\u001b[39m: gtol,\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m: norm,\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m: epsilon,\n\u001b[1;32m   1139\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp,\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: maxiter,\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_all\u001b[39m\u001b[38;5;124m'\u001b[39m: retall}\n\u001b[0;32m-> 1143\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_bfgs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfprime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[1;32m   1146\u001b[0m     retlist \u001b[38;5;241m=\u001b[39m (res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjac\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhess_inv\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   1147\u001b[0m                res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfev\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnjev\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py:1201\u001b[0m, in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxiter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1199\u001b[0m     maxiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x0) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m-> 1201\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1204\u001b[0m f \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun\n\u001b[1;32m   1205\u001b[0m myfprime \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mgrad\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py:261\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    257\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:140\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(grad):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:233\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 233\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:134\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: objective_function() takes 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "lr = MultiClassLogisticRegression(eta=1,\n",
    "                                  iterations=35,\n",
    "                                  C=0.001,\n",
    "                                  solver=BFGSBinaryLogisticRegression,\n",
    "                                  regularization='L2'\n",
    "                                 )\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = lr.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76226573",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sk = SKLogisticRegression(solver='liblinear') # all params default\n",
    "\n",
    "lr_sk.fit(X_train,y_train)\n",
    "yhat = lr_sk.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338fb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d26a318",
   "metadata": {},
   "source": [
    "# 3. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02799f81",
   "metadata": {},
   "source": [
    "# 4. Exceptional Work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
